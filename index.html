<!DOCTYPE html>
<html lang="en">

	<head>

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-120139475-1"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag(){dataLayer.push(arguments);}
			gtag('js', new Date());

			gtag('config', 'UA-120139475-1');
		</script>

		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
		<meta name="description" content="">
		<meta name="author" content="">

		<title>Eklavya Portfolio</title>

		<!-- Bootstrap core CSS -->
		<link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

		<!-- Custom fonts for this template -->
		<link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
		<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
		<link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
		<link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
		<link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

		<!-- Custom styles for this template -->
		<link href="css/resume.min.css" rel="stylesheet">
		<link rel="stylesheet" href="https://cdn.rawgit.com/konpa/devicon/df6431e323547add1b4cf45992913f15286456d3/devicon.min.css">

		<!-- Scripts -->
		<script src="//code.simplesvg.com/1/1.0.0-beta5/simple-svg.min.js"></script>

	</head>

	<body id="page-top">

		<nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
			<a class="navbar-brand js-scroll-trigger" href="#page-top">
				<span class="d-block d-lg-none"></span>
				<span class="d-none d-lg-block">
					<img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.jpg" alt="">
				</span>
			</a>
			<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
				<span class="navbar-toggler-icon"></span>
			</button>
			<div class="collapse navbar-collapse" id="navbarSupportedContent">
				<ul class="navbar-nav">
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#about">About</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#experience">Experience</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#thesis">Thesis</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#projects">Projects</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#talks">Talks</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#competitions">Competitions</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#news">News</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#education">Education</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#skills">Skills</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#extracurricular">Extra-Curricular</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#interests">Interests</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#blog">Blog</a>
					</li>
				</ul>
			</div>
		</nav>

		<div class="container-fluid p-0">
			<section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
				<div class="my-auto">
					<h1 class="mb-0">Eklavya
						<span class="text-primary">Sarkar</span>
					</h1>
					<div class="subheading mb-5">Machine Learning PhD Graduate</div>
					<p>PhD graduate from <a href="https://epfl.ch/">EPFL</a> and Research Assistant at <a href="https://idiap.ch/">Idiap Research Insitute</a>,
	  				<br>in the speech and audio Processing group, under <a href="https://scholar.google.ch/citations?user=_LvtkuAAAAAJ&hl=en">Dr. Mathew Magimai Doss</a>.
	  				<br><br><p>My PhD research focused on self-supervised representation learning for<br>analyzing 
	  				human and non-human vocal communication, for the wider<br>purpose of studying the <a href="https://evolvinglanguage.ch/">evolution of language</a>.</p>
					<br><p>Previously I worked worked on computer vision topics such as deepfakes and face
					<br>morphing, as well as physics research and development at CERN in the CMS experiment.</p>
					<br><br>
					<ul class="list-inline list-social-icons mb-0">
			<li class="list-inline-item">
			  <button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="docs/Resume.pdf">Résumé</a></button>
			</li>
			<li class="list-inline-item">
				<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://scholar.google.com/citations?user=NgOuytoAAAAJ&hl=en">G Scholar</a></button>
			</li>
			<li class="list-inline-item">
				<button type="button" class="btn btn-warning btn-xs"><a target="_blank" style="color:white" href="https://www.linkedin.com/in/eklavyasarkar">LinkedIn</a></button>
			</li>
			<li class="list-inline-item">
				<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="https://github.com/EklavyaFCB">Github</a></button>
			</li>
			<li class="list-inline-item">
				<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://www.kaggle.com/eklavyas">Kaggle</a></button>
			</li>
			<li class="list-inline-item">
			  <button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="https://leetcode.com/eklavya1994/">Leetcode</a></button>
			</li>
			<li class="list-inline-item">
			  <button type="button" class="btn btn-dark btn-xs"><a target="_blank" style="color:white" href="https://medium.com/@eklavyaS">Medium</a></button>
			</li>
			<li class="list-inline-item">
			  <button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="https://eklavya.itch.io/mystery-monkeys">Itch</a></button>
			</li>
			<li class="list-inline-item">
			  <button type="button" class="btn btn-light btn-xs"><a target="_blank" style="color:black" href="mailto:eklavya1994@gmail.com">Email</a></button>
			</li>
					</ul>
				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="publications">
			<div class="my-auto">
			  <h2 class="mb-5">Publications</h2>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Acoustic Tokens</span><span class="badge badge badge-light">Discretization</span><span class="badge badge badge-light">Vector Quantization</span><span class="badge badge badge-light">Bioacoustics</span>
				  <!-- <h3 class="mb-0">On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</h3> -->
				  <div class="subheading mb-3">Leveraging Sequential Structure in Animal Vocalizations</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseAdapt" role="button" aria-expanded="false" aria-controls="collapseAdapt">
					  Abstract
					</a>
				  <div class="collapse" id="collapseAdapt">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, Mathew Magimai-Doss.</b>
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a target="_blank" style="color:white" href="https://publications.idiap.ch/publications/show/5594">Paper</a></button>
				<!-- <button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="">Code</a></button> -->
				<!-- <button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="">Poster</a></button> -->
				<!-- <button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="https://youtu.be/w2lcpwUDY-U">Presentation</a></button> -->
				<!-- <button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_ICASSP_2025_Presentation.pdf">Slides</a></button> -->
				</div>
				<div class="resume-date text-md-right">
				  <!-- <span class="text-primary">Accepted at Bioacoustics &#128211;</span> -->
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Journal</span><span class="badge badge badge-light">Fine-Tuning</span><span class="badge badge badge-light">Speech</span><span class="badge badge badge-light">Bioacoustics</span>
				  <!-- <h3 class="mb-0">On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</h3> -->
				  <div class="subheading mb-3">Adaptation of Speech and Bioacoustics Models</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseAdapt" role="button" aria-expanded="false" aria-controls="collapseAdapt">
					  Abstract
					</a>
				  <div class="collapse" id="collapseAdapt">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, Amir Mohammadi, Mathew Magimai-Doss.</b>
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a target="_blank" style="color:white" href="https://publications.idiap.ch/publications/show/5593">Paper</a></button>
				<!-- <button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="">Code</a></button> -->
				<!-- <button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="">Poster</a></button> -->
				<!-- <button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="https://youtu.be/w2lcpwUDY-U">Presentation</a></button> -->
				<!-- <button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_ICASSP_2025_Presentation.pdf">Slides</a></button> -->
				</div>
				<div class="resume-date text-md-right">
				  <!-- <span class="text-primary">Accepted at Bioacoustics &#128211;</span> -->
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Journal</span><span class="badge badge badge-light">Frequency Response</span><span class="badge badge badge-light">Feature Representation</span><span class="badge badge badge-light">Bioacoustics</span>
				  <!-- <h3 class="mb-0">On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</h3> -->
				  <div class="subheading mb-3">On Feature Representations for Marmoset Vocal Communication Analysis</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseBJ" role="button" aria-expanded="false" aria-controls="collapseBJ">
					  Abstract
					</a>
				  <div class="collapse" id="collapseBJ">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, Mathew Magimai-Doss.</b>
						The acoustic analysis of marmoset (Callithrix jacchus) vocalizations is often used to understand the evolutionary origins of human language. Currently, the analysis is largely carried out in a manual or semi-manual manner. Thus, there is a need to develop automatic call analysis methods. In that direction, research has been limited to the development of analysis methods with small amounts of data or for specific scenarios. Furthermore, there is lack of prior knowledge about what type of information is relevant for different call analysis tasks. To address these issues, as a first step, this paper explores different feature representation methods, namely, HCTSA-based hand-crafted features Catch22, pre-trained self supervised learning (SSL) based features extracted from neural networks trained on human speech and end-to-end acoustic modeling for call-type classification, caller identification and caller sex identification. Through an investigation on three different marmoset call datasets, we demonstrate that SSL-based feature representations and end-to-end acoustic modeling tend to lead to better systems than Catch22 features for call-type and caller classification. Furthermore, we also highlight the impact of signal bandwidth on the obtained task performances.
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a target="_blank" style="color:white" href="https://www.tandfonline.com/eprint/YYC8Q98IDUIZQH7ZZDNY/full?target=10.1080/09524622.2025.2487688">Paper</a></button>
				<!-- <button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="">Code</a></button> -->
				<!-- <button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="">Poster</a></button> -->
				<!-- <button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="https://youtu.be/w2lcpwUDY-U">Presentation</a></button> -->
				<!-- <button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_ICASSP_2025_Presentation.pdf">Slides</a></button> -->
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Accepted at Bioacoustics 2025 &#128211;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Pre-training Domain</span><span class="badge badge badge-light">Fine-Tuning</span><span class="badge badge badge-light">Self-Supervised Learning</span><span class="badge badge badge-light">Bioacoustics</span>
				  <!-- <h3 class="mb-0">On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</h3> -->
				  <div class="subheading mb-3">Comparing Self-Supervised Learning Models Pre-Trained on Human Speech and Animal Vocalizations for Bioacoustics Processing</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseICASSPSSL" role="button" aria-expanded="false" aria-controls="collapseICASSPSSL">
					  Abstract
					</a>
				  <div class="collapse" id="collapseICASSPSSL">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, Mathew Magimai-Doss.</b>
						Self-supervised learning (SSL) foundation models have emerged as powerful, domain-agnostic, general-purpose feature extractors applicable to a wide range of tasks. Such models pre-trained on human speech have demonstrated high transferability for bioacoustic processing. This paper investigates (i) whether SSL models pre-trained directly on animal vocalizations offer a significant advantage over those pre-trained on speech, and (ii) whether fine-tuning speech-pretrained models on automatic speech recognition (ASR) tasks can enhance bioacoustic classification. We conduct a comparative analysis using three diverse bioacoustic datasets and two different bioacoustic tasks. Results indicate that pre-training on bioacoustic data provides only marginal improvements over speech-pretrained models, with comparable performance in most scenarios. Fine-tuning on ASR tasks yields mixed outcomes, suggesting that the general-purpose representations learned during SSL pre-training are already well-suited for bioacoustic tasks. These findings highlight the robustness of speech-pretrained SSL models for bioacoustics and imply that extensive fine-tuning may not be necessary for optimal performance.
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a target="_blank" style="color:white" href="http://arxiv.org/abs/2501.05987">Paper</a></button>
				<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/idiap/ssl-human-animal">Code</a></button>
				<!-- <button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="">Poster</a></button> -->
				<button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="https://youtu.be/w2lcpwUDY-U">Presentation</a></button>
				<button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_ICASSP_2025_Presentation.pdf">Slides</a></button>
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Accepted at ICASSP 2025 &#127470;&#127475;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Foundation Models</span><span class="badge badge badge-light">Pre-training Domain</span><span class="badge badge badge-light">Bandwidth</span><span class="badge badge badge-light">Bioacoustics</span>
				  <!-- <h3 class="mb-0">On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</h3> -->
				  <div class="subheading mb-3">On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseInterUtility" role="button" aria-expanded="false" aria-controls="collapseInterUtility">
					  Abstract
					</a>
				  <div class="collapse" id="collapseInterUtility">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, Mathew Magimai-Doss.</b>
						Marmoset monkeys encode vital information in their calls and serve as a surrogate model for neuro-biologists to understand the evolutionary origins of human vocal communication. Traditionally analyzed with signal processing-based features, recent approaches have utilized self-supervised models pre-trained on human speech for feature extraction, capitalizing on their ability to learn a signal's intrinsic structure independently of its acoustic domain. However, the utility of such foundation models remains unclear for marmoset call analysis in terms of multi-class classification, bandwidth, and pre-training domain. This study assesses feature representations derived from speech and general audio domains, across pre-training bandwidths of 4, 8, and 16 kHz for marmoset call-type and caller classification tasks. Results show that models with higher bandwidth improve performance, and pre-training on speech or general audio yields comparable results, improving over a spectral baseline.
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a target="_blank" style="color:white" href="https://arxiv.org/abs/2407.16417">Paper</a></button>
				<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/idiap/speech-utility-bioacoustics">Code</a></button>
				<!-- <button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="">Poster</a></button> -->
				<!-- <button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="">Presentation</a></button> -->
				<button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_Interspeech_2024_Presentation.pdf">Slides</a></button>
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Accepted at Interspeech 2024 &#127468;&#127479;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Feature Representation</span><span class="badge badge badge-light">Call-Type Classification</span><span class="badge badge badge-light">Bioacoustics</span>
				  <!-- <h3 class="mb-0">On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</h3> -->
				  <div class="subheading mb-3">Feature Representations for Automatic Meerkat Vocalization Classification</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseInterSpeechMeerkat" role="button" aria-expanded="false" aria-controls="collapseInterSpeechMeerkat">
					  Abstract
					</a>
				  <div class="collapse" id="collapseInterSpeechMeerkat">
					<div class="card card-body">
						<b>Authors: Imen Ben Mahoud, Eklavya Sarkar, Marta Manser, Mathew Magimai-Doss.</b>
						Understanding evolution of vocal communication in social animals is an important research problem. In that context, beyond humans, there is an interest in analyzing vocalizations of other social animals such as, meerkats, marmosets, apes. While existing approaches address vocalizations of certain species, a reliable method tailored for meerkat calls is lacking. To that extent, this paper investigates feature representations for automatic meerkat vocalization analysis. Both traditional signal processing-based representations and data-driven representations facilitated by advances in deep learning are explored. Call type classification studies conducted on two data sets reveal that feature extraction methods developed for human speech processing can be effectively employed for automatic meerkat call analysis.
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a target="_blank" style="color:white" href="https://arxiv.org/abs/2408.15296">Paper</a></button>
				<!-- <button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/idiap/speech-utility-bioacoustics">Code</a></button> -->
				<!-- <button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="">Poster</a></button> -->
				<!-- <button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="">Presentation</a></button> -->
				<button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/BenMahoud_Interspeech_2024_Presentation.pdf">Slides</a></button>
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Accepted at Interspeech 2024 &#127468;&#127479;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Cross-Attention</span><span class="badge badge badge-light">Multi-Modal Pre-Training</span><span class="badge badge badge-light">Speech and Text</span>
				  <!-- <h3 class="mb-0">On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis</h3> -->
				  <div class="subheading mb-3">Tokenwise Contrastive Speech and Text Pre-Training for Speech Emotion Recognition</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseTokenwise" role="button" aria-expanded="false" aria-controls="collapseTokenwise">
					  Abstract
					</a>
				  <div class="collapse" id="collapseTokenwise">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, Neha Tarigopula.</b>
						Human emotion recognition involves either decomposing audio signals to reflect the emotion or processing the corresponding text to extract the semantic meaning behind it. In this study, we explore the task of multi-modal emotion recognition by enriching acoustic representations with semantic meaning from the corresponding textual transcript. We use an pre-training strategy to learn the multi-modal representations via contrastive learning of token-by-token alignment of Whisper (speech) and BERT (text) representations using the LibriSpeech dataset. The aligned multi-modal features are then used for training an emotion classifier on IEMOCAP and EmoDB datasets. Despite the multi-modal representations outperforming the BERT-only uni-modal baselines, our results indicate a marginal underperformance compared to the Whisper-only uni-modal model, suggesting that leveraging additional textual information during pre-training might not necessarily improve representations for a downstream emotion recognition task.
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a target="_blank" style="color:white" href="https://publidiap.idiap.ch/publications/show/5662">Paper</a></button>
				<button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_DL4NLP_Presentation.pdf">Slides</a></button>
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Presented at EPFL EE-608 2024 &#x1F1E8;&#x1F1ED;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Self-Supervised Learning</span><span class="badge badge badge-light">Speaker ID</span><span class="badge badge badge-light">Speech</span>
				  <!-- <h3 class="mb-0">Caller Detection</h3> -->
				  <div class="subheading mb-3">Can Self-Supervised Neural Networks Pre-Trained on Human Speech distinguish Animal Callers?</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseInterSpeechMarmoset" role="button" aria-expanded="false" aria-controls="collapseInterSpeechMarmoset">
					  Abstract
					</a>
				  <div class="collapse" id="collapseInterSpeechMarmoset">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, Mathew Magimai-Doss.</b>
						Self-supervised learning (SSL) models use only the intrinsic structure of a given signal, independent of its acoustic domain, to extract essential information from the input to an embedding space. This implies that the utility of such representations is not limited to modeling human speech alone. Building on this understanding, this paper explores the cross-transferability of SSL neural representations learned from human speech to analyze bio-acoustic signals. We conduct a caller discrimination analysis and a caller detection study on Marmoset vocalizations using eleven SSL models pre-trained with various pretext tasks. The results show that the embedding spaces carry meaningful caller information and can successfully distinguish the individual identities of Marmoset callers without fine-tuning. This demonstrates that representations pre-trained on human speech can be effectively applied to the bio-acoustics domain, providing valuable insights for future investigations in this field.
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a style="color:white" href="https://www.isca-archive.org/interspeech_2023/sarkar23_interspeech.html">Paper</a></button>
				<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/idiap/ssl-caller-detection">Code</a></button>
				<!-- <button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="">Poster</a></button> -->
				<button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="https://youtu.be/fU_Pt_OuW1U">Presentation</a></button>
				<button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_Interspeech_2023_Presentation.pdf">Slides</a></button>
				<button type="button" class="btn btn-dark btn-xs"><a target="_blank" style="color:white" href="https://zenodo.org/records/10130104">Dataset</a></button>
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Accepted at Interspeech 2023 &#127470;&#127466;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Signal Processing</span><span class="badge badge badge-light">VAD</span><span class="badge badge badge-light">Speech</span>
				  <!-- <h3 class="mb-0">Voice Activity Detection</h3> -->
				  <div class="subheading mb-3">Unsupervised Voice Activity Detection by Modeling Source and System Information using Zero Frequency Filtering</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseInterSpeechVAD" role="button" aria-expanded="false" aria-controls="collapseInterSpeechVAD">
					  Abstract
					</a>
				  <div class="collapse" id="collapseInterSpeechVAD">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, RaviShankar Prasad, Mathew Magimai-Doss.</b>
						Voice activity detection (VAD) is an important pre-processing step for speech technology applications. The task consists of deriving segment boundaries of audio signals which contain voicing information. In recent years, it has been shown that voice source and vocal tract system information can be extracted using zero-frequency filtering (ZFF) without making any explicit model assumptions about the speech signal. This paper investigates the potential of zero-frequency filtering for jointly modeling voice source and vocal tract system information, and proposes two approaches for VAD. The first approach demarcates voiced regions using a composite signal composed of different zero-frequency filtered signals. The second approach feeds the composite signal as input to the rVAD algorithm. These approaches are compared with other supervised and unsupervised VAD methods in the literature, and are evaluated on the Aurora-2 database, across a range of SNRs (20 to -5 dB). Our studies show that the proposed ZFF-based methods perform comparable to state-of-art VAD methods and are more invariant to added degradation and different channel characteristics. 
					</div>
				  </div>
				  <!-- <button type="button" class="btn btn-success"><a style="color:white" href="">ArXiv</a></button> -->
				<button type="button" class="btn btn-success"><a style="color:white" href="https://www.isca-speech.org/archive/interspeech_2022/sarkar22_interspeech.html">Paper</a></button>
				<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/idiap/zff_vad">Code</a></button>
				<button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_Interspeech_2022_Poster_Landscape.pdf">Poster</a></button>
				<button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="https://youtu.be/hIHLu_7ESfM">Presentation</a></button>
				<button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_Interspeech_2022_Presentation.pdf">Slides</a></button>
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Accepted at Interspeech 2022 &#127472;&#127479;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

<!-- 			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">Pre-print</span><span class="badge badge badge-light">Signal Processing</span><span class="badge badge badge-light">VAD</span><span class="badge badge badge-light">Speech</span>
				  <h3 class="mb-0">Voice Activity Detection</h3>
				  <div class="subheading mb-3">Modeling Source and System characteristics using Zero Frequency Filtering for Voice Activity Detection</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseVAD" role="button" aria-expanded="false" aria-controls="collapseVAD">
					  Abstract
					</a>
				  <div class="collapse" id="collapseVAD">
					<div class="card card-body">
					  Voice activity detection (VAD) is an important pre-processing step for several speech applications. The task requires demarcation of boundaries for segments with voicing information. Several methods in literature perform VAD based on extraction of spectral and temporal information derived across overlapping segments in speech. There are, however, limitations with each approach owing to the underlying decision criterion and thresholding. The present paper proposes a time-domain signal-processing based approach to derive knowledge-based speech specific characteristics for the purpose of VAD. Specifically, we show that extracting source and system characteristics in a framework based on the zero-frequency filtering (ZFF) method, helps in robust identification of segment boundaries with voicing information for a given audio signal. The proposed method is compared with other signal processing based methods which highlight speech specific spectral information. The methods are evaluated for speech segments obtained from TIMIT and MUSAN database, across a range of SNRs (40-0 dB). The analysis shows that the proposed ZFF-based method is robust to degradation and exhibits clear advantage over other spectral information based methods.
					</div>
				  </div>
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">ICASSP 2022 Submission</span>
				  <br><br>
				</div>
			  </div> -->

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">StyleGAN2</span><span class="badge badge badge-light">Face Recognition</span><span class="badge badge badge-light">Biometrics</span>
				  <!-- <h3 class="mb-0">Face Morphing</h3> -->
				  <div class="subheading mb-3">Are GAN-based Morphs Threatening Face Recognition?</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#threats" role="button" aria-expanded="false" aria-controls="threats">
					  Abstract
					</a>
				  <div class="collapse" id="threats">
					<div class="card card-body">
						<b>Authors: Eklavya Sarkar, Pavel Korschunov, Laurent Colbois, Sébastien Marcel.</b>
						Morphing attacks are a threat to biometric systems where the biometric reference in an identity document can be altered. This form of attack presents an important issue in applications relying on identity documents such as border security or access control. Research in generation of face morphs and their detection is developing rapidly, however very few datasets with morphing attacks and open-source detection toolkits are publicly available. This paper bridges this gap by providing two datasets and the corresponding code for four types of morphing attacks: two that rely on facial landmarks based on OpenCV and FaceMorpher, and two that use StyleGAN 2  to generate synthetic morphs. We also conduct extensive experiments to assess the vulnerability of four state-of-the-art face recognition systems, including FaceNet, VGG-Face, ArcFace, and ISV. Surprisingly, the experiments demonstrate that, although visually more appealing, morphs based on StyleGAN 2 do not pose a significant threat to the state to face recognition systems, as these morphs were outmatched by the simple morphs that are based facial landmarks.
					</div>
				  </div>
				<button type="button" class="btn btn-success"><a style="color:white" href="https://ieeexplore.ieee.org/document/9746477">Paper</a></button>
				<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://gitlab.idiap.ch/bob/bob.paper.icassp2022_morph_generate">Code</a></button>
				<button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_ICASSP_2022_Poster.pdf">Poster</a></button>
				<button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="https://youtu.be/anjDrxQKRhc">Presentation</a></button>
				<button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_ICASSP_2022_Presentation.pdf">Slides</a></button>
				<button type="button" class="btn btn-dark btn-xs"><a target="_blank" style="color:white" href="https://zenodo.org/records/4415159">Dataset</a></button>
				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Accepted at ICASSP 2022 &#127480;&#127468;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			  <div class="resume-item d-flex flex-column flex-md-row mb-5">
				<div class="resume-content mr-auto">
				  <span class="badge badge badge-light">StyleGAN2</span><span class="badge badge badge-light">Face Recognition</span><span class="badge badge badge-light">Biometrics</span>
				  <!-- <h3 class="mb-0">Face Morphing</h3> -->
				  <div class="subheading mb-3">Vulnerability Analysis of Face Morphing Attacks from Landmarks and Generative Adversarial Networks</div>
					<a class="btn btn-warning" data-toggle="collapse" href="#collapseExample" role="button" aria-expanded="false" aria-controls="collapseExample">
					  Abstract
					</a>
				  <div class="collapse" id="collapseExample">
					<div class="card card-body">
					  <b>Authors: Eklavya Sarkar, Pavel Korschunov, Laurent Colbois, Sébastien Marcel.</b>
					  Morphing attacks are a threat to biometric systems where the biometric reference in an identity document can be altered. This form of attack presents an important issue in applications relying on identity documents such as border security or access control. Research in face morphing attack detection is developing rapidly, however very few datasets with several forms of attacks are publicly available. This paper bridges this gap by providing a new dataset with four different types of morphing attacks, based on OpenCV, FaceMorpher, WebMorph and a generative adversarial network (StyleGAN), generated with original face images from three public face datasets. We also conduct extensive experiments to assess the vulnerability of the state-of-the-art face recognition systems, notably FaceNet, VGG-Face, and ArcFace. The experiments demonstrate that VGG-Face, while being less accurate face recognition system compared to FaceNet, is also less vulnerable to morphing attacks. Also, we observed that naıve morphs generated with a StyleGAN do not pose a significant threat.
					</div>
				  </div>
				  <button type="button" class="btn btn-success"><a style="color:white" href="https://arxiv.org/abs/2012.05344">Paper</a></button>
				  <button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://gitlab.idiap.ch/biometric/paper.icassp.face-morphing">Code</a></button>
				  <button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/TAM.pdf">Slides</a></button>

				</div>
				<div class="resume-date text-md-right">
				  <span class="text-primary">Presented at Idiap 2020 &#x1F1E8;&#x1F1ED;</span>
				  <br><br>
				  <!-- <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="100" height="100"> -->
				</div>
			  </div>

			</div>
			</section>


			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="experience">
				<div class="my-auto">
					<h2 class="mb-5">Work Experience</h2>

		  <div class="resume-item d-flex flex-column flex-md-row mb-5">
			<div class="resume-content mr-auto">
			  <span class="badge badge badge-light">Speech Processing</span>
			  <h3 class="mb-0">Research Assistant (PhD Candidate)</h3>
			  <div class="subheading mb-3">Idiap Research Institute</div>
			  <p>Supervisor: Dr. Mathew Magimai Doss, Speech and Audio Processing Group</p>
			  <ul>
			  	<li>Self-Supervised Speech Learning, Representation Learning</li>
			  	<li>SSL, VAD, Diarization, ASWUs, Bioacoustics</li>
				<li>Audio Segmentation Methods for Analyzing Vocal Communication: From Humans to Animals.</li>
				<li>Low Resource Speech and Animal Vocalizations processing.</li>
				<li>Working on <a href="https://evolvinglanguage.ch/">EvoLang</a> Project, TTF Tech ASR.</li>
			  </ul>
			</div>
			<div class="resume-date text-md-right">
			  <span class="text-primary">March 2021 - Present</span>
			  <br><br>
			  <img src="img/idiaplogo.jpeg" class="img-thumbnail" width="150" height="100"><br><br>
			  <img src="img/EvoLang.png" class="img-thumbnail" width="150" height="100"><br><br>
			</div>
		  </div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">Biometrics</span><span class="badge badge badge-light">ML</span><span class="badge badge badge-light">DL</span><span class="badge badge badge-light">GANs</span>
							<h3 class="mb-0">Research Intern</h3>
							<div class="subheading mb-3">Idiap Research Institute</div>
							<p>Supervisor: Dr. Sébastien Marcel, HOD Biometrics Security and Privacy Group</p>
							<ul>
								<li>Developed and released StyleGAN2 latent space editing <a href="https://gitlab.idiap.ch/bob/bob.paper.icassp2022_morph_generate">code</a> for morphing.</li>
								<li>Implemented different techniques to generate traditional and StyleGAN2-based face morphs.</li>
								<li>Investigated vulnerabilities of modern facial recognition systems against morphing attacks.</li>
								<li>Currently researching detection techniques for such attacks to publish paper by November. </li>
							</ul>
							<br>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">May 2020 - Feb 2021</span>
			  <br>
			  <span class="text-primary">(10 months)</span>
							<br><br>
							<img src="img/idiaplogo.jpeg" class="img-thumbnail" width="150" height="100"><br><br>
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">SE</span><span class="badge badge badge-light">DS</span></span><span class="badge badge badge-light">R&D</span>
							<h3 class="mb-0">Intern</h3>
							<div class="subheading mb-3">CERN</div>
							<p>Project Manager: Dr. Archana Sharma, Principal Scientist, CMS Experiment</p>
							<ul>
								<li>Contributed to CERN's CMS-GEM-DAQ project's production code: <a href="https://github.com/cms-gem-daq-project/vfatqc-python-scripts/pull/111">PR1</a>, <a href="https://github.com/cms-gem-daq-project/vfatqc-python-scripts/pull/102">PR2</a>.
								<li>Refined efficiency of production code by implementing requested features on Python scripts.</li>
								<li>Improved code used for testing detector in a QC stand by adding an step-size feature.</li>
								<li>Created method for configuring detector’s electrical state with custom values.</li>
								<li>Published real time gas levels of a mixer by writing code to send data to a server via an API.</li>
							</ul>
							<br>
							<button type="button" class="btn btn-warning"><a style="color:black" href="cern.html">More</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">July 2017 - September 2017</span>
							<br>
							<span class="text-primary">(3 months)</span>
							<br><br>
							<img src="img/cernlogo.png" class="img-thumbnail" width="100" height="100"><br><br>
							<img src="img/Cern1.png" class="img-thumbnail" width="200" height="250">
						</div>
					</div>
				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="thesis">
				<div class="my-auto">
					<h2 class="mb-5">Thesis</h2>

						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">DL</span><span class="badge badge badge-light">ML</span><span class="badge badge badge-light">130 Pages</span>
								<h3 class="mb-0">Transferability of Learnt Speech Representations for Decoding Non-Human Vocal Communication
</h3>
								<div class="subheading mb-3"><b>Ph.D.</b>, Speech, Bioacoustics, Animal Vocalizations</div>
								<ul>
									<li style="font-size:14px">Investigated learnt speech representations and their transferability to animal vocalizations.</li>
									<li style="font-size:14px">Published 6+ first-author papers at top ML conferences and journals.</li>
									<li style="font-size:14px">Research topics: speech processing, self-supervised learning, bio-acoustics, speaker diarization, voice activity detection, domain adaption, acoustic sub-word units, and acoustic tokens.</li>
									<li style="font-size:14px">Supervised Interns and Master students.</li>
								</ul>
								<a class="btn btn-warning" data-toggle="collapse" href="#collapsePhDThesis" role="button" aria-expanded="false" aria-controls="collapsePhDThesis">
								  Abstract
								</a>
							  <div class="collapse" id="collapsePhDThesis">
								<div class="card card-body">
									<b>Authors: Eklavya Sarkar</b>
									Humans and animals both use acoustic signals for vocal communication. The advent of self-supervised learning (SSL) has enabled neural networks to learn robust and general feature representations through the intrinsic acoustic structure of input signals, without prior knowledge or supervision. Given that both human speech and animal vocalizations are inherently structured signals that encode information, this thesis investigates whether representations learnt from human speech are transferable for decoding non-human animal vocalizations.
									<br><br>
									We first formulate and validate our core hypothesis through a proof-of-concept caller detection study on marmoset vocalizations, where multiple pre-trained SSL models are benchmarked. Building on this, we further evaluate their transferability across multiple marmoset datasets, and demonstrate that early layer representations from SSL models such as WavLM outperform traditional handcrafted features for call-type and caller identity classification.
									<br><br>
									We then explore how differences in auditory bandwidth between humans and animals influence the transferability of such SSL features. We show that bandwidth mismatches can have an impact on performance, and increasing its size yields a monotonic improvement for call-type and caller classification. We also compare SSL models pre-trained on speech with those pre-trained on general audio or directly on animal vocalizations. Our experiments reveal that general-purpose audio pre-training yields comparable performance to human speech pre-training, and the bioacoustics-trained models marginally improve it on specific datasets.
									<br><br>
									To further improve classification scores, we investigate model adaptation of the pre-trained SSL models. Fine-tuning such speech models on an automatic speech recognition task in a supervised framework does not bring any consistent improvements in performance, and in some cases, actually leads to a performance decline in the later layers. However, parameter-efficient fine-tuning strategies, such as Low-Rank Adaptation (LoRA), combined with selective layer freezing and pruning, achieves significant gains over standard linear probing in specific scenarios, while also reducing training complexity. Our results underscore the importance of LoRA adapter placements, layer selections, and fine-tuning strategies.
									<br><br>
									Finally, we attempt to leverage the sequential nature of animal vocalizations. While previous experiments temporally averaged extracted features into single vector representations, we use vector quantization frameworks to discretize frame-level SSL features into acoustic token sequences. We evaluate these sequences through Levenshtein-distance analysis and sequence classification, and find that while they preserve some degree of acoustic discriminability, their performance remains well below that of a simple linear classifier applied to averaged functional vectors.
									<br><br>
									On the whole, this thesis demonstrates that SSL representations learnt from human speech can generalize effectively to animal vocalizations. Our work provides a practical and robust groundwork for computational bioacoustics, as well as a foundation for further bridging machine learning with animal communication science.
								</div>
							  </div>
								<button type="button" class="btn btn-success"><a style="color:white" href="https://infoscience.epfl.ch/entities/publication/cb827477-ff41-4180-b962-d15b670e0c09">PDF</a></button>
								<button type="button" class="btn btn-secondary btn-xs"><a target="_blank" style="color:white" href="docs/Sarkar_PhD_Presentation.pdf">Slides</a></button>
								<!-- <button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://www.kaggle.com/eklavyas/faceemotionclassification">Code</a></button> -->
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">2021-25</span>
								<br>
				<!-- <span class="text-primary">Grade: <b>Distinction</b></span> -->
				<br><br>
								<img src="img/phd.png" class="img-thumbnail" width="200" height="250">
							</div>
						</div>

						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">DL</span><span class="badge badge badge-light">ML</span><span class="badge badge badge-light">160 Pages</span>
								<h3 class="mb-0">Facial Information Extraction</h3>
								<div class="subheading mb-3"><b>M.Sc.</b>, Computer Vision, Convolutional Neural Networks</div>
								<ul>
									<li style="font-size:14px">Attempted to use state-of-the-art deep learning techniques to build models which take an image as input.</li>
									<li style="font-size:14px">Performed facial detection, recognition, and emotion classification on the present individuals on the images.</li>
									<li style="font-size:14px">Achieved 95% test accuracy on facial recognition with convolutional neural networks and hyper-parameter tuning.</li>
									<li style="font-size:14px">Built separate models for tasks such as emotion classification before combining them into an end-to-end models.</li>
									<li style="font-size:14px">Optimised performance with DL best practices: data augmentation, batch-normalisation, cross-validation. </li>
								</ul>
								<button type="button" class="btn btn-warning"><a style="color:black" href="msc.html">More</a></button>
								<button type="button" class="btn btn-success"><a style="color:white" href="docs/MScThesis.pdf">PDF</a></button>
								<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://www.kaggle.com/eklavyas/faceemotionclassification">Code</a></button>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">2018-19</span>
								<br>
				<span class="text-primary">Grade: <b>Distinction</b></span>
				<br><br>
								<img src="img/FaceReco.png" class="img-thumbnail" width="200" height="250">
							</div>
						</div>
						
						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">SE</span><span class="badge badge badge-light">ML</span><span class="badge badge badge-light">200 Pages</span>
								<h3 class="mb-0">Kohonen Self-Organising Maps</h3>
								<div class="subheading mb-3"><b>B.Sc.</b>, Computer Vision, Pattern Recognition</div>
								<ul>
									<li style="font-size:14px">Implemented unsupervised machine learning neural network from scratch without using any specific ML library.</li>
									<li style="font-size:14px">Trained back-end model on 3 different open-source datasets to test neural network’s efficiency and scalability.</li>
									<li style="font-size:14px">Developed front-end GUI for interactive data visualisation before & after clustering and dimensionality reduction. </li>
									<li style="font-size:14px">Wrote extensive thesis covering all aspects of project such as system design, algorithmic optimisation, scalability.</li>
								</ul>
								<button type="button" class="btn btn-warning"><a style="color:black" href="som.html">More</a></button>
								<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/KohonenThesis.pdf">PDF</a></button>
								<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/EklavyaFCB/EMNIST-Kohonen-SOM">Code</a></button>
								<button type="button" class="btn btn-dark btn-xs"><a target="_blank" style="color:white" href="https://medium.com/p/kohonen-self-organizing-maps-a29040d688da?source=email-e7372da43ed1--writer.postDistributed&sk=ffd8353af86cfcd7e0e52a81364e0346">Medium</a></button>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">2017-18</span>
								<br>
								<span class="text-primary">Grade: <b>90%</b></span>
								<br><br>
								<img src="img/som1.png" class="img-thumbnail" width="200" height="250">
							</div>
						</div>

						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">DS</span><span class="badge badge badge-light">50 Pages</span>
								<h3 class="mb-0">Exoplanets: Discoveries and Prospects</h3>
								<div class="subheading mb-3">Research, Data Analysis, Literature Review</div>
								<ul>
									<li style="font-size:14px"><b>2019 Update: Dider Queloz has since won the Physics Nobel Prize !</b></li>
									<li style="font-size:14px">Conducted literature review on Exoplanets, with inputs from <i>Didier Queloz</i>, co-discoverer of the first exoplanet.</li>
									<li style="font-size:14px">Showed correlations between possibly habitable planets and core laws of physics by analyzing open-source DB.</li>
									<li style="font-size:14px">50 page report selected among top 2013 student scientific projects in Geneva canton and Pays de Gex.</li>
									<li style="font-size:14px">Invited to present project at a public ‘Science Sharing’ event at CERN's <i>Universe de Particules</i> museum.</li>
								</ul>
								<button type="button" class="btn btn-warning"><a style="color:black" href="exoplanets.html">More</a></button>
								<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/exoplanets.pdf">PDF</a></button>
								<button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="docs/ExoplanetsPres.pdf">Presentation</a></button>
								<button type="button" class="btn btn-dark btn-xs"><a target="_blank" style="color:white" href="https://medium.com/p/exoplanets-i-methods-and-discoveries-b653eee48cf2?source=email-e7372da43ed1--writer.postDistributed&sk=795c22a9e388b51e12acfbb79f2fe1db">Medium</a></button>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">2012-13</span>
								<br>
								<span class="text-primary">Grade: <b>6/6</b></span>
								<br><br>
								<img src="img/exoplanets.png" class="img-thumbnail" width="200" height="250">
							</div>
						</div>

			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="projects">
				<div class="my-auto">
					<h2 class="mb-5">Projects and Open-source Contributions</h2>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">RL</span><span class="badge badge badge-light">DL</span><span class="badge badge badge-light">DQN</span><span class="badge badge badge-light">DDPG</span>
							<h3 class="mb-0">Deep Reinforcement Learning: Flappy Bird</h3>
							<div class="subheading mb-3">Deep Q-Learning Network, Deep Deterministic Policy Gradient, Experience Replay</div>
							<p>Attempted to a develop model which is able to learn to play Flappy Bird, and surpass human level scores by using Reinforcement Learning techniques. Specifically investigated Deep Q-Learning networks to develop an overview of the problem and deeper understanding on reinforcement learning techniques. Wished to showcase how computer vision and deep neural networks such as convolutional neural networks can be used in the context of reinforcement learning as well.</p>
							<button type="button" class="btn btn-warning"><a style="color:black" href="https://youtu.be/db9bNbZNRjw">Video</a></button>
							<button type="button" class="btn btn-success"><a style="color:white" href="docs/FlappyBird.pdf">PDF</a></button>
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/EklavyaFCB/FlappyBirdDQN">Code</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2019</span>
							<br><br>
							<img src="img/FlappyBird.png" class="img-thumbnail" width="150" height="150">
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">NLP</span><span class="badge badge badge-light">ML</span><span class="badge badge badge-light">DL</span>
							<h3 class="mb-0">Kaggle Competition: Toxic Comment Classification</h3>
							<div class="subheading mb-3">Multi-Label Classification Problem</div>
							<p>Attempted to solve a Kaggle competition in a group of three to the best of our abilities. Specifically strove for implementations beyond the exsiting classical ones, and attempted to develop a model which is well-adapted and fine tuned to the specific problem at hand. Implemented a Naive-Bayes Bag of Words model, Random Forest, Extra Trees, and compared their results with the Log Regression, Convolutional Neural Network, and Long Short-Term Memory Recurrent models.</p>
							<!--<button type="button" class="btn btn-warning" disabled><a style="color:black">More</a></button>
							<button type="button" class="btn btn-success" disabled><a style="color:white">PDF</a></button>
							<button type="button" class="btn btn-primary btn-xs" disabled><a target="_blank" style="color:white">Code</a></button>-->
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2019</span>
							<br><br>
							<img src="img/ToxicComments.png" class="img-thumbnail" width="150" height="150">
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">ML</span><span class="badge badge badge-light">Bayesian</span><span class="badge badge badge-light">Stats</span>
							<h3 class="mb-0">Bayesian Machine Learning</h3>
							<div class="subheading mb-3">Hamiltonian Monte Carlo Stochastic Methods, Automatic Relevance Determination</div>
							<p>Used Bayesian modelling methods, specifically Hamiltonian Monte Carlo, to approximate Gaussian posterior distributions on a multivariate regression task to derive a good predictor from the dataset, and estimate which of the input variabels are relevant for prediction.</p>
							<!--<button type="button" class="btn btn-warning" disabled><a style="color:black">More</a></button>
							<button type="button" class="btn btn-success" disabled><a style="color:white">PDF</a></button>
							<button type="button" class="btn btn-primary btn-xs" disabled><a target="_blank" style="color:white">Code</a></button>-->
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2019</span>
							<br><br>
							<img src="img/BayesianContour.png" class="img-thumbnail" width="200" height="200">
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">NLP</span><span class="badge badge badge-light">ML</span>
							<h3 class="mb-0">Open Information Extraction</h3>
							<div class="subheading mb-3">Speech Tagging, Named Entity Recognition, Relation Extraction, Kitchen Sink</div>
							<p>Attempted to summarise Jules Verne's 20,000 leagues under the seas' by training a classifier that indicates which of the part of speech tags each word is. The approach was based on <i>Identifying Relations for Open Information Extraction</i> (Fader, Soderland & Etzioni). To this end, Glove word vectors were employed to implement a logistic one vs all kitchen sink model, and attempted speech tagging on word and sentence levels, named entity resolution and relation extraction.</p>
							<!--<button type="button" class="btn btn-warning" disabled><a style="color:black">More</a></button>
							<button type="button" class="btn btn-success" disabled><a style="color:white">PDF</a></button>-->
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" href="https://github.com/EklavyaFCB/OpenInformationExtraction" style="color:white">Code</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2019</span>
							<br><br>
							<img src="img/SpeechTags2.png" class="img-thumbnail" width="250" height="250">
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">SE</span>
							<h3 class="mb-0">Robotics I</h3>
							<div class="subheading mb-3">Localisation, Pathfinding, Navigation, Calibration, Object Detection</div>
							<p>Wrote a program using the Java LeJOS framework that enables a robot to explore the arena which contains a small number of obstacles, placed at random locations. There was a single coloured sheet of paper which the robots had to be able to detect using the colour sensor which also signifed the end location, to which the robot had optimally navigate back to the ending position.</p>
							<button type="button" class="btn btn-warning"><a style="color:black" href="robotics.html">More</a></button>
							<!--<button type="button" class="btn btn-success btn-xs" disabled><a target="_blank" style="color:white">PDF</a></button>-->
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/EklavyaFCB/Robotics1">Code</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2017</span>
							<br><br>
							<img src="img/robo.png" class="img-thumbnail" width="200" height="250">
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">SE</span>
							<h3 class="mb-0">Robotics II</h3>
							<div class="subheading mb-3">Scout, Doctor, Agents, Jason</div>
							<p>Wrote a program using the Java LeJOS framework allowing a robot to determine it's starting location in the arena, and optimally work its way to the pre-determined ending position using scout and doctor agents while avoiding the possible obstacles.</p>
							<button type="button" class="btn btn-warning"><a style="color:black" href="robotics2.html">More</a></button>
							<!--<button type="button" class="btn btn-success btn-xs" disabled><a target="_blank" style="color:white">PDF</a></button>-->
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/EklavyaFCB/Robotics2">Code</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2017</span>
							<br><br>
							<img src="img/trig.png" class="img-thumbnail" width="200" height="250">
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">Android</span><span class="badge badge badge-light">SE</span>
							<h3 class="mb-0">Android Food App</h3>
							<div class="subheading mb-3">Full stack development</div>
							<p>Scran is a user-oriented application that aids in the decision-making process when choosing a restaurant, and more specifically a dish. Scran will maintain, search and track user and restaurant data to help its users to choose the dish they didn’t know they wanted.</p>
							<button type="button" class="btn btn-warning"><a style="color:black" href="scran.html">More</a></button>
							<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/scran.pdf">PDF</a></button>
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/EklavyaFCB/Scran">Code</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2017</span>
							<br><br>
							<img src="img/Scran1.png" class="img-thumbnail" width="150" height="150">
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<span class="badge badge badge-light">SE</span>
							<h3 class="mb-0">Moving Average Filter</h3>
							<div class="subheading mb-3">Generate, Filter and Display data</div>
							<p>Wrote C++ in Xcode to generate random plot and noise values of a sinusoidal function using signal characteristics as parameters, which would then be handled by the designed event driven panels and data structures in LabVIEW, and subsequently transferred to Matlab to be displayed in both filtered and unfiltered states.</p>
							<!--<button type="button" class="btn btn-warning" disabled><a style="color:black">More</a></button>-->
							<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/filtre.pdf">PDF</a></button>
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/EklavyaFCB/Genere_cpp">Code</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2014</span>
							<br><br>
							<img src="img/signal1.png" class="img-thumbnail" width="200" height="250">
						</div>
					</div>

				</div>
				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="talks">
				<div class="my-auto">
					<h2 class="mb-5">Talks</h2>
						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">DL</span><span class="badge badge badge-light">Diarization</span><span class="badge badge badge-light">NCCR</span>
								<h3 class="subheading mb-3">Automatic Speech Segmentation</h3>
								<!-- <div class="subheading mb-3">Speech Diarization</div> -->
								<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/AutoDiarization.pdf">Slides</a></button>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">14 June 2021</span>
<!-- 								<br><br>
								<img src="img/icc.png" class="img-thumbnail" height="500"> -->
							</div>
						</div>

						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">HMM Tutorial Problems</span>
								<h3 class="subheading mb-3">Hidden Markov Models</h3>
								<!-- <div class="subheading mb-3">Speech Diarization</div> -->
								<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/1_HMMs.pdf">Slides (Pt. 1)</a></button>
								<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/2_HMMs.pdf">Slides (Pt. 2)</a></button>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">8 Dec 2020</span>
<!-- 								<br><br>
								<img src="img/icc.png" class="img-thumbnail" height="500"> -->
							</div>
						</div>

						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">DL</span><span class="badge badge badge-light">GANs</span><span class="badge badge badge-light">VAEs</span>
								<h3 class="subheading mb-3">Generative Adversarial Networks</h3>
								<!-- <div class="subheading mb-3">Speech Diarization</div> -->
								<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/GANs.pdf">Slides</a></button>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">30 April 2020</span>
<!-- 								<br><br>
								<img src="img/icc.png" class="img-thumbnail" height="500"> -->
							</div>
						</div>

						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">DL</span><span class="badge badge badge-light">CNNs</span>
								<h3 class="subheading mb-3">Convolutional Neural Networks</h3>
								<!-- <div class="subheading mb-3">Speech Diarization</div> -->
								<button type="button" class="btn btn-success btn-xs"><a target="_blank" style="color:white" href="docs/CNNs.pdf">Slides</a></button>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">30 April 2020</span>
<!-- 								<br><br>
								<img src="img/icc.png" class="img-thumbnail" height="500"> -->
							</div>
						</div>
				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="competitions">
				<div class="my-auto">
					<h2 class="mb-5">Competitions</h2>

						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">3rd Prize</span><span class="badge badge badge-light">DL</span>
								<h3 class="mb-0">International Create Challenge</h3>
								<div class="subheading mb-3">Adversarial Attacks</div>
								<p></p>
								<ul>
									<li>Developed model to detect and combat adversarial attacks using Foolbox toolkit.</li>
									<li>Implemented website to evaluate the robutness of a given model to adversarial attacks using a specific metric.</li>
									<li>Awarded 3rd place in overall ICC2020.</li>
								</ul>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">2020</span>
								<br><br>
								<img src="img/icc.png" class="img-thumbnail" height="500">
							</div>
						</div>

						<div class="resume-item d-flex flex-column flex-md-row mb-5">
							<div class="resume-content mr-auto">
								<span class="badge badge badge-light">SE</span><span class="badge badge badge-light">iOS</span>
								<h3 class="mb-0">Facebook Hackathon 2015</h3>
								<div class="subheading mb-3">iOS Revision App</div>
								<p>Developed iOS app with first generation Swift on xCode.</p>
								<ul>
									<li>Goal was to give students a platform to revise and prepare for exams on the go.</li>
									<li>Content specifically tailored to the common first-year Bachelor course.</li>
									<li>Option of adding content for additional modules and courses by users.</li>
									<li>Hopefully improve the student pass rate at EPFL by providing feedback and tips.</li>
								</ul>
								<br>
								<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://github.com/EklavyaFCB/EPFL-Revisions">Code</a></button>
							</div>
							<div class="resume-date text-md-right">
								<span class="text-primary">2015</span>
								<br><br>
								<img src="img/FacebookLogo2.png" class="img-thumbnail" width="100">
							</div>
						</div>
				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="news">
				<div class="my-auto">
					<h2 class="mb-5">News</h2>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<h3 class="mb-0">CERN Intern</h3>
							<div class="subheading mb-3">Featured on University of Liverpool Student News</div>
							<p><a href="https://student-news.liverpool.ac.uk/2017/11/16/student-feature-summer-internship-cern/">FULL Student feature: My summer Internship at CERN</a></p>
							<p>"<i>Arriving wide-eyed at the main lab on the first day, I discovered that I was among twenty other excited students, from all over the world, ranging from Thailand, Brazil, France, US, India, Italy and many others, all of whom had arrived at different moments during the summer, meaning there was little time for individual introductions to the lab and explanations of the various hardware components and the software code base.</i>"</p>
							<button type="button" class="btn btn-warning"><a style="color:black" href="news.html">More</a></button>
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://student-news.liverpool.ac.uk/2017/11/16/student-feature-summer-internship-cern">Link</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">October 2017</span>
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<h3 class="mb-0">Exoplanet Project Presentation</h3>
							<div class="subheading mb-3">Featured on Colloc Transfrontalier TPE-TM</div>
							<p>Selected to present on stage my research project on Exoplanets at the <i>Colloque Transfrontalier: La Science en Partage</i> (a public ‘Science Sharing’ event) at CERN’s Universe of Particles museum.</p>
							<button type="button" class="btn btn-warning"><a style="color:black" href="news2.html">More</a></button>
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://indico.cern.ch/event/236737/overview">Link</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">October 2013</span>
							<br><br>
							<img src="img/CernPic.png" class="img-thumbnail" width="300">
						</div>
					</div>

				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="education">
				<div class="my-auto">
					<h2 class="mb-5">Education</h2>

					<div class="resume-item d-flex flex-column flex-md-row">
						<div class="resume-content mr-auto">
							<h3 class="mb-0">Ecole Polytechnique Fédérale de Lausanne</h3>
							<div class="subheading mb-3">PhD Machine Learning</div>
							<div>- Deep Learning</div>
							<div>- Graph Machine Learning</div>
							<div>- Deep Learning for Natural Language Processing</div>
							<div>- Science and Engineering Teaching and Learning</div>
							<br>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">March 2021 - Present</span>
							<br>
							<span class="text-primary">Grade: <b>5.2/6</b></span>
							<br><br>
							<img src="img/epfl.png" class="rounded" width="150">
						</div>
					</div>
					<br>
					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<h3 class="mb-0">University of Bath</h3>
							<div class="subheading mb-3">MSc Data Science</div>
							<div>- Statistics</div>
							<div>- Machine Learning I & II</div>
							<div>- Neural Computing</div>
							<div>- Bayesian Machine Learning</div>
							<div>- Reinforcement Learning</div>
							<div>- Applied Data Science</div>
							<div>- Software technologies for data science</div>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">October 2018 - September 2019</span>
							<br>
							<span class="text-primary">Grade: <b>First Class</b></span>
							<br><br>
							<img src="img/bath.png" class="rounded" width="150">
						</div>
					</div>
					<br>
					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<h3 class="mb-0">University of Liverpool</h3>
							<div class="subheading mb-3">BSc Computer Science</div>
							<div>- Efficient Sequential Algorithms, Complexity of Algorithms</div>
							<div>- Robotics and Autonomous Systems, Multi-System Agents</div>
							<div>- Biocomputation, Artificial Intelligence</div>
							<div>- Complex Information and Social Networks</div>
							<div>- Software Engineering, Group Software Project</div>
							<div>- Automata Theory</div>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">September 2015 - June 2018</span>
							<br>
							<span class="text-primary">Grade: <b>First Class</b></span>
							<br><br>
							<img src="img/uol.png" class="rounded" width="150">
						</div>
					</div>

<!-- 					<div class="resume-item d-flex flex-column flex-md-row">
						<div class="resume-content mr-auto">
							<h3 class="mb-0">Ecole Polytechnique Fédérale de Lausanne</h3>
							<div class="subheading mb-3">BSc Mechanical Engineering</div>
							<div>- Calculus I & II</div>
							<div>- Linear Algebra</div>
							<div>- General Physics I & II</div>
							<div>- Material Science</div>
							<div>- Mechanics of Structure, Mechanical Conception</div>
							<br>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">September 2013 - June 2015</span>
							<br>
							<span class="text-primary">(Uncompleted)</span>
							<br><br>
							<img src="img/epfl.png" class="rounded" width="150">
						</div>
					</div> -->
				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="skills">
				<div class="my-auto">
					<h2 class="mb-5">Skills</h2>
					<ul class="list-inline list-icons">
						<li class="list-inline-item">
							<i class="devicon-java-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-javascript-plain colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-python-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-mysql-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-jquery-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-php-plain colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-cplusplus-plain colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-bootstrap-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-html5-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-css3-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-git-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-github-plain-wordmark colored"></i>
						</li>
						<li class="list-inline-item">
							<i class="devicon-d3js-plain colored"></i>
						</li>
					</ul>

					<div class="subheading mb-3">Languages and Libraries</div>
						<ul class="fa-ul mb-0">
							<li>
								<i class="fa-li fa fa-check"></i>
								Python: PyTorch, Hydra, Optuna, Sci-kit Learn, OpenCV, SeaBorn, Flask, Pandas, NumPy, Matplotlib</li>
							<li>
								<i class="fa-li fa fa-check"></i>
								Java: LeJOS</li>
							<li>
								<i class="fa-li fa fa-check"></i>
								Javascript: D3.js, jQuery, AJAX</li>
							<li>
								<i class="fa-li fa fa-check"></i>
								SQL: MySQL, MySQL Workbench</li>
							<li>
								<i class="fa-li fa fa-check"></i>
								C++: Cern's ROOT</li>
							<li>
								<i class="fa-li fa fa-check"></i>
								PHP</li>
							<li>
								<i class="fa-li fa fa-check"></i>
								Tex</li>
							<li>
								<i class="fa-li fa fa-check"></i>
								Bash, Shell Scripting</li>
							<li>
								<i class="fa-li fa fa-check"></i>
								HTML, CSS: Bootstrap</li>
						</ul>
				</div>

				<div class="my-auto">
					<div class="subheading mb-3">Tools and Technologies</div>
					 <ul class="fa-ul mb-0">
						<li>
							<i class="fa-li fa fa-check"></i>
							Git, Github</li>
						<li>
						<li>
							<i class="fa-li fa fa-check"></i>
							Slurm, Sun Grid Engine (SGE) Scheduler</li>
						<li>
							<i class="fa-li fa fa-check"></i>
							Unix, Linux</li>
						<li>
							<i class="fa-li fa fa-check"></i>
							VSCode</li>
						<li>
							<i class="fa-li fa fa-check"></i>
							Mattermost, Slack</li>
						<li>
							<i class="fa-li fa fa-check"></i>
							Shell, Bash, Zsh, Tmux, Byobu</li>
						<li>
					</ul>
				 </div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="extracurricular">
				<div class="my-auto">
					<h2 class="mb-5">Extra-Curricular</h2>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<h3 class="mb-0">Organizer</h3>
							<div class="subheading mb-3">Perspectives on AI Symposium Series</div>
							<ul>
								<li>Participated in the conception and organization of the series along PIs.</li>
								<li>Responsible for developing the vision, design, and implementation of the event <a href="https://pai.idiap.ch/">website</a>.</li>
								<li>Helped in finding sponsors, budgeting, and overall event management.</li>
							</ul>
							<br>
							<button type="button" class="btn btn-primary btn-xs"><a target="_blank" style="color:white" href="https://pai.idiap.ch/">Website</a></button>
							<button type="button" class="btn btn-danger btn-xs"><a target="_blank" style="color:white" href="https://www.youtube.com/playlist?app=desktop&list=PLUqt83brHwngpBhCHG0c0R57UuZ7ia6j0">Clips</a></button>
							<button type="button" class="btn btn-info btn-xs"><a target="_blank" style="color:white" href="https://watch.klewel.com/watch/search?query=Idiap+Symposium+Series+-+Perspectives+on+AI">Presentations</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2022-24</span>
							<br><br>
							<img src="img/pai.png" class="rounded" width="300">
						</div>
					</div>

					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<h3 class="mb-0">President</h3>
							<div class="subheading mb-3">Student Residence Hall's Committee</div>
							<ul>
								<li>Elected President of Hall Committee by ballot vote majority to represent 270 students.</li>
								<li>Enhanced residents’ experience by taking charge and managing events throughout the year.</li>
								<li>Responsible for formulating outline and implementation of vision for Hall’s community and life.</li>
								<li>Led 10 member committee through generating team vision and chairing weekly meetings.</li>
								<li>Maintained professional relationship with residence staff, guild of students, accommodation office and the university.</li>
							</ul>
							<br>
							<button type="button" class="btn btn-warning"><a style="color:black" href="hsc.html">More</a></button>
						</div>
						<div class="resume-date text-md-right">
							<span class="text-primary">2017-18</span>
							<br><br>
							<img src="img/guild.png" class="rounded" width="150">
						</div>
					</div>
				
				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="interests">
				<div class="my-auto">
					<h2 class="mb-5">Interests</h2>
		  <ul class="fa-ul mb-0">
			<li>
			  <i class="fa-li fa fa-heart text-warning"></i>
			  Dance: Bachata (Geneva Bachata Festival 2024, 25), Salsa
			</li>
			<li>
			  <i class="fa-li fa fas fa-gamepad text-warning"></i>
			  <a href="https://eklavya.itch.io/mystery-monkeys">Indie Game Development</a>
			</li>
			<li>
			  <i class="fa-li fa fa-futbol-o text-warning"></i>
			  <a href="http://www.barcelonafootballblog.com/20697/view-stands-spain-chile/">Football Blog posts</a>
			</li>
			<li>
			  <i class="fa-li fa fa-first-order text-warning"></i>
			  Game of Thrones Expert
			</li>
			<li>
			  <i class="fa-li fa fa-paint-brush text-warning"></i>
			  Art - Graphic Design, Wacom Tablet
			</li>
			<li>
			  <i class="fa-li fa fa-trophy text-warning"></i>
			  Martial Arts - Karaté Green Belt
			</li>
			<li>
			  <i class="fa-li fa fa-trophy text-warning"></i>
			  Swimming - UK Swimathon 2018, 1.5 km challenge
			</li>
			<li>
			  <i class="fa-li fa fa-video-camera text-warning"></i>
			  Film - Brighton Film School, Summer Filmmaking Diploma
			</li>
			<li>
			  <i class="fa-li fa fa-handshake-o text-warning"></i>
			  Project Why NGO Volunteer, New Delhi, India
			</li>
			<li>
			  <i class="fa-li fa fa-snowflake-o text-warning"></i>
			  Skiing
			</li>
		  </ul>
				</div>
			</section>

			<section class="resume-section p-3 p-lg-5 d-flex flex-column" id="blog">
				<div class="my-auto">
					<h2 class="mb-5">Blog</h2>
					<div class="resume-item d-flex flex-column flex-md-row mb-5">
						<div class="resume-content mr-auto">
							<!-- <h3 class="mb-0">PhD Musings</h3>
							<div class="subheading mb-3">Office Open-Secrets</div>
							<a class="btn btn-warning" data-toggle="collapse" href="#oos" role="button" aria-expanded="false" aria-controls="oos">Read</a>
						  	<div class="collapse" id="oos">
							<div class="card card-body">
								Gotcha.
							</div>
						  	</div>
							<br><br>
							<div class="subheading mb-3">Supervisor-supervisee relatonship</div>
							<a class="btn btn-warning" data-toggle="collapse" href="#ss" role="button" aria-expanded="false" aria-controls="oos">Read</a>
						  	<div class="collapse" id="ss">
							<div class="card card-body">
								Lorem Ipsum.
							</div>
						  	</div>
							<br><br> -->
							<h3 class="mb-0">Game Reviews</h3>
								<div class="subheading mb-3">The Last of Us: Part II</div>
								<a class="btn btn-warning" data-toggle="collapse" href="#tlou2" role="button" aria-expanded="false" aria-controls="tlou2">
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
								</a>
							  	<div class="collapse" id="tlou2">
								<div class="card card-body">
									<b>An absolute powerhouse experience of an odyssey-level story.</b>
									<br>
									<ul class="list-group">
									  <li class="list-group-item list-group-item-success">Gripping, complex, layered, and emotional story leading to an overall very heavy, raw, and visceral experience. Set in the backdrop of a very well realized collapsed society, the storytelling itself is also as exceptional as the story. Every single cutscene feels absolutely <i>earned</i> after difficult and often long sequences. Certain cutscenes left my hand shaking. Despite not being an "horror" game, it is a very anxiety-inducing and frightening game. I've never felt so much dread in a game ever. But at the same time the game is groundbreaking, focusing primarily on the themes of loss, grief, the cycle of violence, and the price ultimately one pays to pursue revenge and retribution.</li>
									  <li class="list-group-item list-group-item-success">Very refined and heart-stopping gameplay, including stealth, adventure-action, and puzzles. There are a number of sequences that just feel unreal. Game also keeps evolving and adding new enemy factions and mechanisms. Overall I found the game quite 'hard' to play, but it's also very hard to pick a "favourite part", as there are so simply too many !</li>
									  <li class="list-group-item list-group-item-success">Captivating, complex, and fully realized primary and supporting characters. The 19 year old Ellie is really something to behold.</li>
									  <li class="list-group-item list-group-item-success">The most beautiful game visuals you might ever see. The fires and forests especially stand out.</li>
									  <li class="list-group-item list-group-item-success">Phenomenal, movie-level game audio and sound, which change the tone and move the story beats ever so slightly.</li>
									  <li class="list-group-item list-group-item-danger">Game should've been slightly shorter, though I can see what they were going for. It's purposefully intended that you feel the drag as you go into the final act. Regardless, I think one starts caring less at this point as the catharsis still hasn't happened.</li>
									  <li class="list-group-item list-group-item-danger">I felt like the game should've had around three jump scares less, most of those being in the first half.</li>
									<br>
									Overall, undoubtedly one of the best games ever to have ever been made, successfully transcending any 'genre', and perhaps my favorite. An ambitious masterpiece by Naughty Dog, and a deserving successor that even surpasses the original game.
								</div>
							  	</div>
							  	<br><br>
								<div class="subheading mb-3">Cyberpunk 2077</div>
								<a class="btn btn-warning" data-toggle="collapse" href="#cb" role="button" aria-expanded="false" aria-controls="cb">
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
								</a>
							  	<div class="collapse" id="cb">
								<div class="card card-body">
									<b>An absolute blaze of glory and an experience of a lifetime.</b>
									<br>
									<ul class="list-group">
									  <li class="list-group-item list-group-item-success">Immersive world and story which quickly grip you right from the start. Pacing is pretty good, and things move at a reasonable pace. The story is of a significant size and each act is pretty long, but well-executed.</li>
									  <li class="list-group-item list-group-item-success">Perhaps the most 'sci-fi' game I've ever played. Each element, from the menu, to the world design is impressive, well thought through, and developed.</li>
									  <li class="list-group-item list-group-item-success">Story, mission design, and visual design are very diverse and entertaining. Night City is a vibrant and atmospheric metropolis and amazing to explore especially at night.</li>
									  <li class="list-group-item list-group-item-success">Arguably the greatest ever made DLC expands the game even more.</li>
									  <li class="list-group-item list-group-item-danger">There is a bit too much dialogue for me, towards the end I would stop reading and just click on any option.</li>
									  <li class="list-group-item list-group-item-danger">Despite being mostly bug-free, there were still a few repetitive bugs which made the experience less enjoyable. But kudos for the team to keep releasing patches and novel content.</li>
									</ul>
									  <br>
									  All in all, there might be some minor flaws, but those pale in comparaison to the mammoth storytelling experience and ambitiousness of the whole game. Leaves you with unforgettable feelings when the credits finally roll. 
								</div>
							  	</div>
							  	<br><br>
								<div class="subheading mb-3">Marvel's Spider-Man</div>
								<a class="btn btn-warning" data-toggle="collapse" href="#sm1" role="button" aria-expanded="false" aria-controls="sm1">
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
									<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-star-fill" viewBox="0 0 16 16">
	  								<path d="M3.612 15.443c-.386.198-.824-.149-.746-.592l.83-4.73L.173 6.765c-.329-.314-.158-.888.283-.95l4.898-.696L7.538.792c.197-.39.73-.39.927 0l2.184 4.327 4.898.696c.441.062.612.636.282.95l-3.522 3.356.83 4.73c.078.443-.36.79-.746.592L8 13.187l-4.389 2.256z"/>
									</svg>
								</a>
							  	<div class="collapse" id="sm1">
								<div class="card card-body">
									<b>A phenomenally polished game that encompasses everything one could ever want in a spidey-game !</b>
									<br>
									<ul class="list-group">
									  <li class="list-group-item list-group-item-success">Arguably the best spider-man story ever told on screen. Light-hearted, engaging, fun, yet serious and compelling when needed, it's a full-course balanced meal of Peter Parker.</li>
									  <li class="list-group-item list-group-item-success">Extremely well polished game, visually. The graphics are high-quality and highly optimized, giving a very smooth experience. The first time playing, it feels like living in the future, when one can fully swing around in a fully-realized NYC, at day or night.</li>
									  <li class="list-group-item list-group-item-success">The wide variety of suits, gadgets, podcasts, and side-quests really animate the NYC open-world.</li>
									</ul>
									<br>
									Overall, perhaps the greatest and most satisfying superhero game ever made through love and passion for the titular character. An absolute blast from the start to the end. No negatives.
								</div>
							  	</div>
						</div>
					</div>
				</div>
			</section>


		</div>

		<!-- Bootstrap core JavaScript -->
		<script src="vendor/jquery/jquery.min.js"></script>
		<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

		<!-- Plugin JavaScript -->
		<script src="vendor/jquery-easing/jquery.easing.min.js"></script>

		<!-- Custom scripts for this template -->
		<script src="js/resume.min.js"></script>

	</body>

</html>
